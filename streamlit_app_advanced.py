import streamlit as st
import pandas as pd
from pathlib import Path
from datetime import datetime
import tempfile
import traceback

# Import z moduÅ‚Ã³w
from processing import load_xlsx
import reports as rpt
from export_excel import write_report_xlsx

# KolejnoÅ›Ä‡ arkuszy
SHEET_ORDER = [
    "summary",
    "package_type_share",
    "hourly_dims_measured",
    "hourly_weight_measured",
    "loop_99",
    "nok_244",
    "overflow_243",
    "hourly_loop_nok_ovf",
    "chute_full",
    "problem_share_type",
    "bad_dims_pct",
    "bad_weight_pct",
    "top5_heaviest",
    "top5_lightest",
]

# Opisy (tekst + pozycja bloku)
DESCRIPTIONS = {
    "package_type_share": ("""Ta tabela przedstawia iloÅ›ciowy i procentowy rozkÅ‚ad opakowaÅ„ na instalacji wraz z ich wymiarami

Opis kolumn:

package_type - typ opakowania
avg_lenght - Å›rednia dÅ‚ugoÅ›Ä‡ paczki danego typu w mm
avg_width - Å›rednia szerokoÅ›Ä‡  paczki danego typu w mm
avg_height - Å›rednia wysokoÅ›Ä‡  paczki danego typu w mm
items_count_all - ile paczek danego typu wystÄ…piÅ‚o na instalacji
pct_share - procentowy rozkÅ‚ad opakowaÅ„

Åšrednie liczone dla opakowaÅ„ zmierzonych, dziÄ™ki czemu nieopomiarowane opakowanie nie zaniÅ¼ajÄ… Å›redniej. IloÅ›ci to wszystkie opakowania danego typu, w tym nieopomiarowane. To podejÅ›cie zapewnia duÅ¼Ä… precyzyjnoÅ›Ä‡ danych

Tabela posortowana wedÅ‚ug opakowaÅ„ najczÄ™Å›ciej wystÄ™pujÄ…cych, majÄ…cych najwiÄ™kszy udziaÅ‚ w rozkÅ‚adzie
                           
avg_len to Å›rednia dÅ‚ugoÅ›Ä‡ wszystkich paczek na instalacji (Å›rednia waÅ¼ona)
predicted_eff to przewidywana wydajnoÅ›Ä‡ sortera przy zaÅ‚oÅ¼eniu, Å¼e Å›rednia dÅ‚ugoÅ›Ä‡ paczek 400mm daje wydajnoÅ›Ä‡ 8500 (zgodnie z dokumentacjÄ…)
                           
https://drive.google.com/file/d/1g8EU9LQgIKa3NrOvm24-8AwQVLDlzRYW/view?usp=sharing



""", "I4", "O22"),
    "hourly_dims_measured": ("""Ta tabela przedstawia Å›rednie wymiary paczek w rozkÅ‚adzie godzinowym oraz jakoÅ›Ä‡ pomiarÃ³w

Opis kolumn:
scan_hour - znacznik czasu
package_type - typ opakowania
avg_lenght - Å›rednia dÅ‚ugoÅ›Ä‡ paczki danego typu w mm
avg_width - Å›rednia szerokoÅ›Ä‡  paczki danego typu w mm
avg_height - Å›rednia wysokoÅ›Ä‡  paczki danego typu w mm
total_items - wszystkie paczki zarejestrowane na instalacji
unmensured_items - iloÅ›Ä‡ paczek niezmierzonych
pct_unmeasured - procent paczek niezmierzonych

Åšrednie liczone dla opakowaÅ„ zmierzonych, dziÄ™ki czemu nieopomiarowane opakowanie nie zaniÅ¼ajÄ… Å›redniej. Niezwymiarowanych jest niewiele, dziÄ™ki czemu dane sÄ… obarczone niskim bÅ‚Ä™dem


""", "K4", "Q22"),
    "loop_99": ("""Ta tabela przedstawia wszystkie paczki wysÅ‚ane do loop i ile razy

Opis kolumn:

scan_date - znacznik czasu
chunk - numer danej paczki zawarty na etykiecie wysyÅ‚kowej
package_type - typ opakowania
discharge - gdzie posortowano (loop)
items_count- ile razy dana paczka trafiÅ‚a do loop

JeÅ›li dana paczka trafiÅ‚a do loop wiÄ™cej razy niÅ¼ okreÅ›la to system, wskazuje to na problem (np. krÄ…Å¼enie paczek danego typu)

JeÅ›li pojawiÅ‚y siÄ™ paczki, ktÃ³re majÄ… brak chunku (w kolumnie chunk) sÄ… one grupowane i zliczane po typie opakowania (nie musi byÄ‡ to jedna i ta sama paczka)

""", "H3", "N18"),
    "nok_244": ("""Ta tabela przedstawia wszystkie paczki posortowane do zrzutni nok 244 i ile razy

Opis kolumn:

scan_date - znacznik czasu
chunk - numer danej paczki zawarty na etykiecie wysyÅ‚kowej
package_type - typ opakowania
discharge - gdzie posortowano (nok 244)
items_count- ile razy dana paczka trafiÅ‚a do nok 244

JeÅ›li dana paczka trafiÅ‚a wielokrotnie do nok, wskazuje to na problem

JeÅ›li pojawiÅ‚y siÄ™ paczki, ktÃ³re majÄ… brak chunku (w kolumnie chunk) sÄ… one grupowane i zliczane po typie opakowania (nie musi byÄ‡ to jedna i ta sama paczka)

""", "H4", "N19"),
    "overflow_243": ("""Ta tabela przedstawia wszystkie paczki posortowane do zrzutni overflow i ile razy

Opis kolumn:

scan_date - znacznik czasu
chunk - numer danej paczki zawarty na etykiecie wysyÅ‚kowej
package_type - typ opakowania
discharge - gdzie posortowano (overflow 243)
items_count- ile razy dana paczka trafiÅ‚a do overflow 243

JeÅ›li dana paczka trafiÅ‚a wielokrotnie do overflow, wskazuje to na problem
                     
JeÅ›li pojawiÅ‚y siÄ™ paczki, ktÃ³re majÄ… brak chunku (w kolumnie chunk) sÄ… one grupowane i zliczane po typie opakowania (nie musi byÄ‡ to jedna i ta sama paczka)

""", "H4", "N19"),
    "hourly_loop_nok_ovf": ("""Ta tabela przedstawia, ile paczek w kaÅ¼dej godzinie trafia do loop, overflow, nok w odniesieniu do wszystkich paczek zarejestrowanych na instalacji

Opis kolumn:

scan_hour - znacznik czasu
total_items - wszystkie rzeczy zarejestrowane na instalacji
loop_99_count - iloÅ›Ä‡ paczek posortowanych do loop
overflow_243_count - iloÅ›Ä‡ paczek posortowana do zrzutni overflow 243
nok_count - iloÅ›Ä‡ paczek posortowana do zrzutni nok 244

""", "H4", "N19"),
    "chute_full": ("""Ta tabela przedstawia, ile paczek z powodu chute full dana zrzutnia wysÅ‚aÅ‚a na loop lub - jeÅ›li siÄ™ zdarzy - do overflow i nok

Opis kolumn:

discharge - gdzie posortowano (loop, overflow, nok)
logic - zawiera numer zrzutni i powÃ³d (chute full)
items_count - iloÅ›Ä‡ paczek
                   
""", "F4", "L19"),
    "problem_share_type": ("""Ta tabela przedstawia, jaki typ opakowania ma najwiÄ™cej procent wysyÅ‚ania do loop bÄ…dÅº overflow czy nok

Opis kolumn:

package_type - zawiera kod opakowania
total_items - iloÅ›Ä‡ paczek danego typu zarejestrowano na instalacji
discharge - gdzie posortowano (loop, overflow, nok) 
problem_items - ile paczek z danego typu posortowano do loop, overflow, nok
pct_of_type - ile paczek z danego typu procentowo posortowano do loop, overflow, nok
                           
Tabela posortowana wedÅ‚ug kolumny pct_of_type malejÄ…co. 

""", "H4", "N19"),
    "bad_dims_pct": ("""Ta tabela przedstawia jakoÅ›Ä‡ wymiarowania danych opakowaÅ„

Opis kolumn:

type - typ opakowania
bad_meaasurements - ile razy paczki z danym typem opakowania nie byÅ‚o zwymiarowane
total_items - ile razy dany typ opakowania wystÄ…piÅ‚ na instalacji
pct_bad - ile procent opakowaÅ„ danego typu nie jest wymiarowanych przez instalacjÄ™

""", "G3", "M18"),
    "bad_weight_pct": ("""Ta tabela przedstawia jakoÅ›Ä‡ waÅ¼enia danych opakowaÅ„

Opis kolumn:

type - typ opakowania
bad_weight - ile razy paczki z danym typem opakowania nie byÅ‚o zwaÅ¼one
total_items - ile razy dany typ opakowania wystÄ…piÅ‚ na instalacji
pct_bad_weight - ile procent opakowaÅ„ danego typu nie jest waÅ¼onych przez instalacjÄ™

""", "G4", "M19"),

    "hourly_weight_measured": ("""Ta tabela przedstawia Å›redniÄ… masÄ™ paczek (kolumna Volume (waga) - masa w gramach) oraz skutecznoÅ›Ä‡ waÅ¼enia w ujÄ™ciu godzinowym.
avg_weight: Å›rednia masa [g] 
measured_items: liczba paczek z masÄ… 
unmeasured_items: niezwaÅ¼one paczki
pct_unmeasured: % paczek bez poprawnej masy""", "I2", "N6"),

    "top5_heaviest": ("""TOP 5 najciÄ™Å¼szych paczek.
Kolumny:
chunk - Chunk Id
type - Package type Barcodes
weight - masa [g]""", "I2", "N6"),

    "top5_lightest": ("""TOP 5 najlÅ¼ejszych paczek.
Kolumny:
chunk - Chunk Id
type - Package type Barcodes
weight - masa [g]""", "I2", "N6"),
}


def generate_report(uploaded_file):
    """GÅ‚Ã³wna funkcja generujÄ…ca raport"""
    try:
        # Zapisz tymczasowo plik
        with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_input:
            tmp_input.write(uploaded_file.getvalue())
            tmp_input_path = tmp_input.name

        # Wczytaj dane
        st.info(f"ğŸ“‚ WczytujÄ™ plik: {uploaded_file.name}")
        loaded = load_xlsx(tmp_input_path)

        if loaded.min_scan is None or loaded.max_scan is None:
            raise RuntimeError("Nie udaÅ‚o siÄ™ sparsowaÄ‡ kolumny Scan (brak dat).")

        st.success(f"ğŸ“… Zakres czasu: {loaded.min_scan} â†’ {loaded.max_scan}")
        st.info(f"ğŸ“Š Wierszy w pliku: {len(loaded.df):,}")

        if len(loaded.df) == 0:
            raise RuntimeError("Plik po wczytaniu ma 0 wierszy.")

        # Liczenie raportÃ³w
        st.info("âš™ï¸ Liczenie raportÃ³w...")
        progress_bar = st.progress(0)
        sheets = {}

        sheets["bad_dims_pct"] = rpt.report_bad_dims_pct(loaded.df)
        progress_bar.progress(10)
        
        sheets["bad_weight_pct"] = rpt.report_bad_weight_pct(loaded.df)
        progress_bar.progress(20)
        
        sheets["package_type_share"] = rpt.report_package_type_dims_share(loaded.df)
        progress_bar.progress(30)

        sheets["loop_99"] = rpt.report_discharge_detail(loaded.df, "99 Loop")
        progress_bar.progress(40)
        
        sheets["nok_244"] = rpt.report_discharge_detail(loaded.df, "Not Ok 244")
        progress_bar.progress(50)
        
        sheets["overflow_243"] = rpt.report_discharge_detail(loaded.df, "Overflow 243")
        progress_bar.progress(60)

        sheets["hourly_loop_nok_ovf"] = rpt.report_hourly_loop_nok_overflow(loaded.df)
        progress_bar.progress(70)
        
        sheets["hourly_dims_measured"] = rpt.report_hourly_dims_measured(loaded.df)
        progress_bar.progress(78)
        
        sheets["hourly_weight_measured"] = rpt.report_hourly_weight_measured(loaded.df)
        progress_bar.progress(82)
        sheets["chute_full"] = rpt.report_chute_full(loaded.df)
        progress_bar.progress(90)
        
        sheets["problem_share_type"] = rpt.report_problem_share_type(loaded.df, min_total=50)
        progress_bar.progress(94)

        top_heavy, top_light = rpt.report_top5_weight_extremes(loaded.df)
        sheets["top5_heaviest"] = top_heavy
        sheets["top5_lightest"] = top_light
        progress_bar.progress(95)
        # Policz Å›redniÄ… waÅ¼onÄ… i prognozowanÄ… wydajnoÅ›Ä‡
        wavg_len, pred_eff = rpt.compute_weighted_length_and_efficiency(
            sheets["package_type_share"],
            base_efficiency=8500.0,
            base_avg_length=400.0,
        )

        # Zapisz raport do tymczasowego pliku
        with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_output:
            tmp_output_path = Path(tmp_output.name)

        # --- SUMMARY sheet (do Excela jako pierwszy arkusz) ---
        total_rows = int(len(loaded.df))
        avg_length_mm = float(wavg_len) if pd.notna(wavg_len) else float("nan")
        total_length_km = (total_rows * avg_length_mm / 1_000_000) if pd.notna(avg_length_mm) else 0.0

        vol = pd.to_numeric(loaded.df.get("Volume"), errors="coerce")
        total_mass_g = vol[vol > 0].sum() if vol is not None else 0.0
        total_mass_t = float(total_mass_g) / 1_000_000

        if loaded.min_scan and loaded.max_scan:
            scan_min = loaded.min_scan.strftime("%Y-%m-%d")
            scan_max = loaded.max_scan.strftime("%Y-%m-%d")
            scan_label = scan_max if scan_min == scan_max else f"{scan_min} â†’ {scan_max}"
        else:
            scan_label = "brak"

        sheets["summary"] = pd.DataFrame([{
            "scan": scan_label,
            "rows": total_rows,
            "avg_length_mm": round(avg_length_mm, 2) if pd.notna(avg_length_mm) else pd.NA,
            "total_length_km": round(total_length_km, 2),
            "total_mass_t": round(total_mass_t, 3),
        }])

        write_report_xlsx(
            tmp_output_path,
            sheets,
            sheet_order=SHEET_ORDER,
            descriptions=DESCRIPTIONS,
            package_type_share_summary=(wavg_len, pred_eff),
        )
        
        progress_bar.progress(100)
        st.success("âœ… Raport wygenerowany!")

        # ZwrÃ³Ä‡ plik do pobrania i dane do wizualizacji
        with open(tmp_output_path, 'rb') as f:
            return f.read(), tmp_output_path.name, sheets, (wavg_len, pred_eff), loaded

    except Exception as e:
        st.error(f"âŒ BÅ‚Ä…d: {e}")
        with st.expander("ğŸ“‹ SzczegÃ³Å‚y bÅ‚Ä™du"):
            st.code(traceback.format_exc())
        return None, None, None, None, None



def show_visualizations(sheets, summary, loaded):
    """WyÅ›wietl wizualizacje danych"""
    wavg_len, pred_eff = summary

    st.markdown("### ğŸ“Š Podsumowanie")

    # KPI bazowe
    rows = int(len(loaded.df))
    avg_length_mm = float(wavg_len) if pd.notna(wavg_len) else float("nan")
    total_length_km = (rows * avg_length_mm / 1_000_000) if pd.notna(avg_length_mm) else 0.0

    # Volume = masa w gramach
    vol = pd.to_numeric(loaded.df.get("Volume"), errors="coerce")
    total_mass_g = vol[vol > 0].sum() if vol is not None else 0.0
    total_mass_t = float(total_mass_g) / 1_000_000  # g -> t

    # Data (Scan)
    if loaded.min_scan and loaded.max_scan:
        if loaded.min_scan.date() == loaded.max_scan.date():
            scan_label = loaded.max_scan.strftime("%Y-%m-%d")
        else:
            scan_label = f"{loaded.min_scan.strftime('%Y-%m-%d')} â†’ {loaded.max_scan.strftime('%Y-%m-%d')}"
    else:
        scan_label = "brak"

    # SkutecznoÅ›ci waÅ¼one (sum(measured)/sum(total))
    dims_eff = None
    if "hourly_dims_measured" in sheets:
        d = sheets["hourly_dims_measured"]
        if "measured_items" in d.columns and "total_items" in d.columns and d["total_items"].sum() > 0:
            dims_eff = float(d["measured_items"].sum() / d["total_items"].sum() * 100.0)

    weight_eff = None
    if "hourly_weight_measured" in sheets:
        w = sheets["hourly_weight_measured"]
        if "measured_items" in w.columns and "total_items" in w.columns and w["total_items"].sum() > 0:
            weight_eff = float(w["measured_items"].sum() / w["total_items"].sum() * 100.0)

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Data", scan_label)
    with col2:
        st.metric("Przeprocesowane paczki", f"{rows}")
    with col3:
        st.metric("Åšrednia dÅ‚ugoÅ›Ä‡ paczek", f"{avg_length_mm:.2f} mm" if pd.notna(avg_length_mm) else "brak")
    with col4:
        st.metric("Prognozowana wydajnoÅ›Ä‡ sortera", f"{pred_eff}")

    col5, col6, col7, col8 = st.columns(4)
    with col5:
        st.metric("Przeprocesowana dÅ‚ugoÅ›Ä‡ paczek", f"{total_length_km:.2f} km")
    with col6:
        st.metric("Przeprocesowana masa paczek", f"{total_mass_t:.3f} t")
    with col7:
        st.metric("SkutecznoÅ›Ä‡ mierzenia", f"{dims_eff:.2f}%" if dims_eff is not None else "brak")
    with col8:
        st.metric("SkutecznoÅ›Ä‡ waÅ¼enia", f"{weight_eff:.2f}%" if weight_eff is not None else "brak")

    # 1) Top 10 typÃ³w opakowaÅ„
    if "package_type_share" in sheets:
        st.markdown("### ğŸ“¦ Top 10 typÃ³w opakowaÅ„")
        df = sheets["package_type_share"].head(10).copy()
        st.bar_chart(df.set_index("package_type")["items_count_all"])

    # 2) Wolumen caÅ‚kowity w czasie (godzinowo)
    if "hourly_loop_nok_ovf" in sheets:
        st.markdown("### ğŸ“ˆ Wolumen caÅ‚kowity w czasie")
        hourly_df = sheets["hourly_loop_nok_ovf"].copy()
        if "scan_hour" in hourly_df.columns and "total_items" in hourly_df.columns:
            hourly_df["scan_hour"] = pd.to_datetime(hourly_df["scan_hour"])
            hourly_df = hourly_df.set_index("scan_hour").sort_index()
            st.area_chart(hourly_df[["total_items"]])

    # 3) SkutecznoÅ›Ä‡ mierzenia i waÅ¼enia (godzinowo)
    st.markdown("### âœ… SkutecznoÅ›Ä‡ mierzenia i waÅ¼enia (godzinowo)")
    eff_df = None

    if "hourly_dims_measured" in sheets:
        d = sheets["hourly_dims_measured"].copy()
        if "scan_hour" in d.columns:
            d["scan_hour"] = pd.to_datetime(d["scan_hour"])
            d = d.set_index("scan_hour").sort_index()
            if "pct_unmeasured" in d.columns:
                eff_df = pd.DataFrame({"skutecznoÅ›Ä‡_mierzenia_%": (100.0 - d["pct_unmeasured"]).round(2)})

    if "hourly_weight_measured" in sheets:
        w = sheets["hourly_weight_measured"].copy()
        if "scan_hour" in w.columns:
            w["scan_hour"] = pd.to_datetime(w["scan_hour"])
            w = w.set_index("scan_hour").sort_index()
            if "pct_unmeasured" in w.columns:
                w_eff = pd.DataFrame({"skutecznoÅ›Ä‡_waÅ¼enia_%": (100.0 - w["pct_unmeasured"]).round(2)})
                eff_df = w_eff if eff_df is None else eff_df.join(w_eff, how="outer")

    if eff_df is not None and not eff_df.empty:
        st.line_chart(eff_df)
    else:
        st.info("Brak danych do wykresu skutecznoÅ›ci.")

    # 4) Problemy w czasie (Loop, NOK, Overflow) - liczby bezwzglÄ™dne
    if "hourly_loop_nok_ovf" in sheets:
        st.markdown("### âš ï¸ Loop, NOK, Overflow w czasie")
        prob_df = sheets["hourly_loop_nok_ovf"].copy()
        if "scan_hour" in prob_df.columns:
            prob_df["scan_hour"] = pd.to_datetime(prob_df["scan_hour"])
            prob_df = prob_df.set_index("scan_hour").sort_index()
            problem_cols = ["loop_99_count", "overflow_243_count", "nok_count"]
            available_cols = [c for c in problem_cols if c in prob_df.columns]
            if available_cols:
                st.line_chart(prob_df[available_cols])
            
                # 4a) Analiza problemÃ³w jako procent caÅ‚oÅ›ci
                st.markdown("### âš ï¸ Loop, NOK, Overflow jako procent wolumenu")
                if "total_items" in prob_df.columns:
                    pct = prob_df[available_cols].div(prob_df["total_items"], axis=0) * 100.0
                    st.line_chart(pct)

    # 5) JakoÅ›Ä‡ pomiarÃ³w (tylko pojedyncze typy w aplikacji)
    if "bad_dims_pct" in sheets and "bad_weight_pct" in sheets:
        st.markdown("### ğŸ“ JakoÅ›Ä‡ pomiarÃ³w â€“ pojedyncze typy")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**Wymiary - Top 5 problemowych**")
            bad_dims = sheets["bad_dims_pct"].copy()
            if "type" in bad_dims.columns:
                bad_dims = bad_dims[~bad_dims["type"].astype(str).str.contains(";", regex=False)]
            st.dataframe(bad_dims.head(5), hide_index=True, use_container_width=True)

        with col2:
            st.markdown("**Masa - Top 5 problemowych**")
            bad_weight = sheets["bad_weight_pct"].copy()
            if "type" in bad_weight.columns:
                bad_weight = bad_weight[~bad_weight["type"].astype(str).str.contains(";", regex=False)]
            st.dataframe(bad_weight.head(5), hide_index=True, use_container_width=True)

    # 6) Ekstrema masy (TOP 5) â€“ tylko pojedyncze typy w aplikacji
    if "top5_heaviest" in sheets and "top5_lightest" in sheets:
        st.markdown("### ğŸ‹ï¸ Ekstrema masy (TOP 5) â€“ pojedyncze typy ")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**TOP 5 najciÄ™Å¼szych**")
            top_heavy = sheets["top5_heaviest"].copy()
            if "type" in top_heavy.columns:
                top_heavy = top_heavy[~top_heavy["type"].astype(str).str.contains(";", regex=False)]
            st.dataframe(top_heavy.head(5), hide_index=True, use_container_width=True)

        with col2:
            st.markdown("**TOP 5 najlÅ¼ejszych**")
            top_light = sheets["top5_lightest"].copy()
            if "type" in top_light.columns:
                top_light = top_light[~top_light["type"].astype(str).str.contains(";", regex=False)]
            st.dataframe(top_light.head(5), hide_index=True, use_container_width=True)

def main():
    # Konfiguracja strony
    st.set_page_config(
        page_title="Analizator BOX 5000 Ultra",
        page_icon="ğŸ“¦",
        layout="wide"
    )

    # TytuÅ‚ i opis
    st.title("ğŸ“¦ Analizator BOX 5000 Ultra")
    st.markdown("*Profesjonalna analiza danych w kilka sekund*")
    st.markdown("---")
    
    # Sidebar z informacjami
    with st.sidebar:
        st.markdown("### â„¹ï¸ Informacje")
        st.markdown("""
        **Raport zawiera:**
        - ğŸ“Š RozkÅ‚ad typÃ³w opakowaÅ„
        - â±ï¸ Analiza godzinowa
        - ğŸ”„ SzczegÃ³Å‚y Loop/NOK/Overflow
        - ğŸ“ JakoÅ›Ä‡ pomiarÃ³w
        - âš¡ Prognoza wydajnoÅ›ci
        
        **Limity:**
        - Max: ~100k wierszy 
        - Formaty: XLSX
        - Czas: ~30-60 sek
        """)
        
        st.markdown("---")
        st.markdown("### ğŸ¨ Opcje")
        show_preview = st.checkbox("PokaÅ¼ wizualizacje", value=True)
        show_data_preview = st.checkbox("PokaÅ¼ podglÄ…d tabel", value=True)
    
    # GÅ‚Ã³wna zawartoÅ›Ä‡
    st.markdown("""
    ### ğŸš€ Jak uÅ¼ywaÄ‡:
    1. **Wgraj plik XLSX** z danymi MFC/Maintenace/Box sort detail
    2. **Kliknij "Generuj raport"** i poczekaj ~30-60 sekund
    3. **Obejrzyj** raport na stronie lub **pobierz** table z opisem w pliku Excel
    """)
    
    st.markdown("---")

    # Upload pliku
    uploaded_file = st.file_uploader(
        "ğŸ“ Wybierz plik XLSX do analizy",
        type=['xlsx'],
        help="Plik musi zawieraÄ‡ kolumnÄ™ 'Scan' z datami oraz dane logistyczne (Discharge, Package type, etc.)"
    )

    if uploaded_file is not None:
        # WyÅ›wietl info o pliku
        file_size_mb = uploaded_file.size / 1024 / 1024
        st.info(f"ğŸ“„ Wybrany plik: **{uploaded_file.name}** ({file_size_mb:.2f} MB)")
        
        # Przycisk generowania
        if st.button("ğŸš€ Generuj raport", type="primary", use_container_width=True):
            with st.spinner("ğŸ”„ Przetwarzam dane... To moÅ¼e potrwaÄ‡ ~30-60 sekund"):
                report_data, _, sheets, summary, loaded = generate_report(uploaded_file)
                
                if report_data and sheets and summary and loaded:
                    # Zapisz w session state
                    st.session_state['report_data'] = report_data
                    st.session_state['sheets'] = sheets
                    st.session_state['summary'] = summary
                    st.session_state['loaded'] = loaded
                    st.session_state['uploaded_filename'] = uploaded_file.name
                    
                    st.balloons()
                    st.success("ğŸ‰ Raport gotowy do pobrania!")

    # JeÅ›li raport zostaÅ‚ wygenerowany, pokaÅ¼ przycisk pobierania i wizualizacje
    if 'report_data' in st.session_state:
        st.markdown("---")
        
        # Przycisk pobierania
        stamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        filename = f"BOX_raport_{stamp}.xlsx"
        
        st.download_button(
            label="â¬‡ï¸ Pobierz raport Excel",
            data=st.session_state['report_data'],
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary",
            use_container_width=True
        )
        
        # Wizualizacje
        if show_preview:
            st.markdown("---")
            show_visualizations(
                st.session_state['sheets'],
                st.session_state['summary'],
                st.session_state['loaded']
            )
        
        # PodglÄ…d tabel
        if show_data_preview:
            st.markdown("---")
            st.markdown("### ğŸ“‹ PodglÄ…d danych")
            
            # Tabele w tej samej kolejnoÅ›ci co arkusze w wygenerowanym XLSX
            ordered = [n for n in SHEET_ORDER if n in st.session_state['sheets']]
            for n in st.session_state['sheets'].keys():
                if n not in ordered:
                    ordered.append(n)

            tabs = st.tabs(ordered)

            for i, name in enumerate(ordered):
                df = st.session_state['sheets'][name]
                with tabs[i]:
                    st.markdown(f"**{name}** - Pokazuje pierwsze 50 wierszy")
                    st.dataframe(df.head(50), use_container_width=True, hide_index=True)

    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666; padding: 20px;'>
        <small>ğŸ“¦ Analizator BOX 5000 Ultra | Wersja webowa </small>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
